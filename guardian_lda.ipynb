{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eMj8v2cc60yy",
    "outputId": "4fac9b78-ccce-4c05-cfa1-369c94c63433"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# !pip install -U gensim\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uly-u05A7F9Q",
    "outputId": "dbbbec74-95c3-4584-8965-6b1a093c35a5"
   },
   "outputs": [],
   "source": [
    "# Loading the datasets\n",
    "\n",
    "guard_df = pd.read_csv('/Users/sketcha/lda/guardian.csv', sep=',')\n",
    "print('For Guardian original Number of Columns: {}, rows: {}'.format(guard_df.shape[1], guard_df.shape[0]) )\n",
    "\n",
    "columns = ['firstPublicationDate', 'webUrl', 'bodyText']\n",
    "guard_df = guard_df[columns]\n",
    "guard_df.drop_duplicates(subset =\"bodyText\", inplace = True)\n",
    "\n",
    "print(guard_df.shape)\n",
    "guard_df.dropna(inplace=True)\n",
    "\n",
    "guard_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "tjqC-b2g7eKP",
    "outputId": "37762890-c07d-4350-deb6-710bb05274db"
   },
   "outputs": [],
   "source": [
    "# Pre-processing steps\n",
    "\n",
    "%timeit\n",
    "# initalizing the werdnet lemmatizer\n",
    "lm = WordNetLemmatizer()\n",
    "# creating a new column to store rows after processing\n",
    "guard_df['post_processed'] = np.nan\n",
    "\n",
    "stopwords.extend(['advertisement', 'supported'])\n",
    "def processing(content):\n",
    "\n",
    "    content = content.split(' ')\n",
    "#   removing stopwords\n",
    "    content = [word.strip().lower() for word in content if word.lower() not in stopwords]\n",
    "#   removing punctuations\n",
    "    rx = re.compile('([&#.:?!-()])*')\n",
    "    content = [rx.sub('', word) for word in content]\n",
    "    \n",
    "    content = [word for word in content if len(word)>1 and word.isalpha()]\n",
    "#   lemmatizing    \n",
    "    content = [lm.lemmatize(word) for word in content]\n",
    "\n",
    "    return ' '.join(content)\n",
    "\n",
    "# removing opinion articles\n",
    "for i in range(len(guard_df)):\n",
    "    if 'opinion' not in guard_df.iloc[i,1]:\n",
    "        guard_df.iloc[i,-1] = processing(guard_df.iloc[i,2]) \n",
    "\n",
    "\n",
    "guard_df.dropna(inplace=True)\n",
    "guard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zPA1XjjC_wY2",
    "outputId": "66992e44-2d21-4449-b104-bce8224d8063"
   },
   "outputs": [],
   "source": [
    "# Frequency filtering\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "#decomposing sentences into tokens \n",
    "tokens = [sentence.split(' ') for sentence in guard_df['post_processed'] ]\n",
    "\n",
    "# Create Dictionary\n",
    "dct = corpora.Dictionary(tokens)\n",
    "print('Unique words before filtering', len(dct))\n",
    "# no_below= 30\n",
    "dct.filter_extremes(no_below= 20, no_above=0.25 )\n",
    "print('Unique words after filtering', len(dct))\n",
    "# Create Corpus\n",
    "corpus = [dct.doc2bow(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coherence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtaining coherence results\n",
    "\n",
    "%%time\n",
    "from gensim.models import CoherenceModel\n",
    "import time\n",
    "\n",
    "scores = []\n",
    "for k in range(1,26):\n",
    "  lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dct, num_topics=k, \n",
    "                                       random_state=100, chunksize=128, passes=10,\n",
    "                                       per_word_topics=True)\n",
    "\n",
    "  coherence_model_lda = CoherenceModel(model=lda_model, texts=tokens, dictionary=dct, coherence='c_v')\n",
    "  coherence_lda = coherence_model_lda.get_coherence()\n",
    "  print( 'coherence_lda', coherence_lda)\n",
    "  # time.sleep(20)\n",
    "\n",
    "  scores.append(coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "cpVkAWTn1Cl9",
    "outputId": "5bd0bdc1-2139-45ba-f1c5-ccf650a6e56e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting coherence results\n",
    "\n",
    "selected_topics = np.argmax(scores)+3\n",
    "plt.plot(list(range(1,26)), scores, color= \"green\")\n",
    "plt.xlabel('Number of topics')\n",
    "plt.ylabel('Coherence Scores')\n",
    "plt.savefig('guardian_coherence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Final Model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqKFlbJM1TlW"
   },
   "outputs": [],
   "source": [
    "# constructing the lda model\n",
    "\n",
    "selected_topics = 7\n",
    "\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dct, num_topics=selected_topics, \n",
    "                                           random_state=100, chunksize=128, passes=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save lda model \n",
    "lda_model.save(\"guardian.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "id": "qVzoHzOO1ane",
    "outputId": "32ef5983-631c-4bc6-884c-0313cc27bf11",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "# import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim_models.prepare(lda_model, corpus, dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to use the style, you must put the 'apa.mplstyle' file inside of 'stylelib' folder. please see: https://github.com/sollan/apa.mplstyle\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.style.use(matplotlib.get_data_path()+'/stylelib/apa.mplstyle') # selecting the style sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelling the topics \n",
    "\n",
    "topic_names = ['Sports', 'Vaccination',  'Policy', 'Economy', 'U.S Politics', 'Travel Restrictions',\n",
    "               'Australian News']\n",
    "predicted_topics = lda_model[corpus]\n",
    "\n",
    "probs, topics = [], []\n",
    "for k in predicted_topics:\n",
    "  # print(k)\n",
    "  k.sort(key=lambda x:x[1])\n",
    "  topics.append(topic_names[ k[0][0] ] ), probs.append(k[0][1])\n",
    "\n",
    "guard_df['Predicted Topic'] = topics\n",
    "guard_df['Probability'] = probs\n",
    "\n",
    "dates = [row.split('T')[0] for row in guard_df['firstPublicationDate'] ]\n",
    "guard_df['firstPublicationDate'] = dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "Cm9ALZX63q6U",
    "outputId": "bc4f5fae-2717-4a84-eafe-bbeca7e30b6c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting for the topics discussed in the results section only\n",
    "\n",
    "topic_name = ['Economy', 'Travel Restrictions', 'U.S Politics', 'Vaccination' ]\n",
    "\n",
    "guard_df['new_date'] =  pd.to_datetime(guard_df['firstPublicationDate'], format='%Y-%m-%d')\n",
    "guard_df = guard_df.set_index('new_date', drop=True)\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(topics_name)):\n",
    "    \n",
    "    x = guard_df[guard_df['Predicted Topic'] == topic_names[i] ]\n",
    "    curr = x.groupby(x.index.strftime('%Y-%m')).count()\n",
    "    curr = curr.reset_index()\n",
    "    curr['x_axis'] = pd.to_datetime(curr['new_date'], format='%Y-%m')\n",
    "    \n",
    "    plt.plot(curr.x_axis, curr['Predicted Topic'], label=topics_name[i] )\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('nyt_results_topics_plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting for the topics \"Vaccination\" and \"Travel Restrictions\"\n",
    "\n",
    "topic_name = ['Vaccination', 'Travel Restrictions' ]\n",
    "\n",
    "guard_df['new_date'] =  pd.to_datetime(guard_df['firstPublicationDate'], format='%Y-%m-%d')\n",
    "guard_df = guard_df.set_index('new_date', drop=True)\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(topics_name)):\n",
    "    \n",
    "    x = guard_df[guard_df['Predicted Topic'] == topic_names[i] ]\n",
    "    curr = x.groupby(x.index.strftime('%Y-%m')).count()\n",
    "    curr = curr.reset_index()\n",
    "    curr['x_axis'] = pd.to_datetime(curr['new_date'], format='%Y-%m')\n",
    "    \n",
    "    plt.plot(curr.x_axis, curr['Predicted Topic'], label=topics_name[i] )\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('guardian_vaccine_travel_plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "hqJ_Cmz81NM9",
    "outputId": "f8a206d5-6f0d-435b-e4bf-e47ac3635f98",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting for the topic \"Economy\"\n",
    "\n",
    "topic_name = ['Economy']\n",
    "\n",
    "guard_df['new_date'] =  pd.to_datetime(guard_df['firstPublicationDate'], format='%Y-%m-%d')\n",
    "guard_df = guard_df.set_index('new_date', drop=True)\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(topics_name)):\n",
    "    \n",
    "    x = guard_df[guard_df['Predicted Topic'] == topic_names[i] ]\n",
    "    curr = x.groupby(x.index.strftime('%Y-%m')).count()\n",
    "    curr = curr.reset_index()\n",
    "    curr['x_axis'] = pd.to_datetime(curr['new_date'], format='%Y-%m')\n",
    "    \n",
    "    plt.plot(curr.x_axis, curr['Predicted Topic'], label=topics_name[i] )\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('nyt_economy_plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting for the topic \"U.S Politics\"\n",
    "\n",
    "topic_name = ['U.S Politics']\n",
    "\n",
    "guard_df['new_date'] =  pd.to_datetime(guard_df['firstPublicationDate'], format='%Y-%m-%d')\n",
    "guard_df = guard_df.set_index('new_date', drop=True)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "for i in range(len(topics_name)):\n",
    "    \n",
    "    x = guard_df[guard_df['Predicted Topic'] == topic_names[i] ]\n",
    "    curr = x.groupby(x.index.strftime('%Y-%m')).count()\n",
    "    curr = curr.reset_index()\n",
    "    curr['x_axis'] = pd.to_datetime(curr['new_date'], format='%Y-%m')\n",
    "    \n",
    "    plt.plot(curr.x_axis, curr['Predicted Topic'], label=topics_name[i] )\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('guardian_uspolitics_plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLiY0LTU_sIa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.to_csv('topics.csv', index=True, columns=['firstPublicationDate', 'bodyText', 'Predicted Topic'], sep=',')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cemkoy_guardian.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
