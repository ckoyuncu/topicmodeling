{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyCYYXIH4GfC",
    "outputId": "62c4720a-e5ac-45e3-ac86-628d0dcc5878"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "# !pip install -U gensim\n",
    "stopwords = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "hvjEPhiH4hUF",
    "outputId": "76c67773-87c5-4756-83f1-bdd50b928da1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the datasets\n",
    "\n",
    "nyt_df = pd.read_csv('/Users/sketcha/lda/nyt.csv', sep=',')\n",
    "print('Original Number of Columns: {}, rows: {}'.format(nyt_df.shape[1], nyt_df.shape[0]) )\n",
    "\n",
    "columns = ['pub_date', 'web_url','content']\n",
    "nyt_df = nyt_df[columns]\n",
    "nyt_df.drop_duplicates(subset =\"content\", inplace = True)\n",
    "\n",
    "print(nyt_df.shape)\n",
    "nyt_df.dropna(inplace=True)\n",
    "\n",
    "nyt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "77W3e7GO6s-x",
    "outputId": "91c484a9-1b31-4f21-d856-755f64f88203",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-processing steps\n",
    "\n",
    "%timeit\n",
    "# initalizing the werdnet lemmatizer\n",
    "lm = WordNetLemmatizer()\n",
    "# creating a new column to store rows after processing\n",
    "nyt_df['post_processed'] = ''\n",
    "\n",
    "stopwords.extend(['advertisement', 'supported'])\n",
    "# stopwords.extend(['rt'])\n",
    "def processing(content):\n",
    "\n",
    "    content = content.split(' ')\n",
    "#     removing stopwords\n",
    "    content = [word.strip().lower() for word in content if word.lower() not in stopwords]\n",
    "#     removing punctuations\n",
    "    rx = re.compile('([&#.:?!-()])*')\n",
    "    content = [rx.sub('', word) for word in content]\n",
    "    \n",
    "    content = [word for word in content if len(word)>1 and word.isalpha()]\n",
    "#   lemmatizing  \n",
    "    content = [lm.lemmatize(word) for word in content]\n",
    "\n",
    "    return ' '.join(content)\n",
    "\n",
    "# removing opinion articles\n",
    "for i in range(len(nyt_df)):\n",
    "    if 'opinion' not in nyt_df.iloc[i,1]:\n",
    "        nyt_df.iloc[i,-1] = processing(nyt_df.iloc[i,2])\n",
    "        \n",
    "\n",
    "nyt_df.dropna(inplace=True)\n",
    "nyt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLs1P4XpDamm",
    "outputId": "c847cbca-bae8-4cad-a49d-4cd6edf68b3e"
   },
   "outputs": [],
   "source": [
    "# Frequency filtering\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "#decomposing sentences into tokens \n",
    "tokens = [sentence.split(' ') for sentence in nyt_df['post_processed'] ]\n",
    "\n",
    "# Create Dictionary\n",
    "dct = corpora.Dictionary(tokens)\n",
    "print('Unique words before filtering', len(dct))\n",
    "# no_below= 20\n",
    "dct.filter_extremes(no_below= 20, no_above=0.25 )\n",
    "print('Unique words after filtering', len(dct))\n",
    "# Create Corpus\n",
    "corpus = [dct.doc2bow(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coherence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngn-GXKMQvtx",
    "outputId": "f1739610-dd28-4e53-97e6-1abe74a76ad2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtaining coherence results\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "scores = []\n",
    "for k in range(1,26):\n",
    "  lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dct, num_topics=k, \n",
    "                                       random_state=100, chunksize=128, passes=10,\n",
    "                                       per_word_topics=True)\n",
    "\n",
    "  coherence_model_lda = CoherenceModel(model=lda_model, texts=tokens, dictionary=dct, coherence='c_v')\n",
    "  coherence_lda = coherence_model_lda.get_coherence()\n",
    "  print( 'coherence_lda', coherence_lda)\n",
    "\n",
    "  scores.append(coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "dabl6BAjRC6p",
    "outputId": "337bf0fd-b8d5-4cc3-ce39-dd075fef6ffe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting coherence results\n",
    "\n",
    "selected_topics = np.argmax(scores)+3\n",
    "plt.plot(list(range(1,26)), scores, color= \"blue\")\n",
    "plt.xlabel('Number of topics')\n",
    "plt.ylabel('Coherence Scores')\n",
    "plt.savefig('nyt_coherence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDeB5Vo0gIMf"
   },
   "source": [
    "**Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uevekUUgGUo"
   },
   "outputs": [],
   "source": [
    "# constructing the lda model\n",
    "\n",
    "selected_topics= 6\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dct, num_topics=selected_topics, \n",
    "                                           random_state=100, chunksize=128, passes=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save lda model \n",
    "lda_model.save(\"nyt.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "id": "Z1JclQm5RRSm",
    "outputId": "28fc4b3c-c15d-4cbd-d96d-e788936e97b4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "# import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim_models.prepare(lda_model, corpus, dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mkorw09URSwn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Labeling the topics\n",
    "topics_name = ['Sports', 'Community',  'U.S Politics', 'Economy', 'Travel Restrictions', 'Vaccination', 'Travel Restrictions']\n",
    "predicted_topics = lda_model[corpus]\n",
    "\n",
    "probs, topics = [], []\n",
    "for k in predicted_topics:\n",
    "  # print(k)\n",
    "  k.sort(key=lambda x:x[1])\n",
    "  topics.append(topics_name[ k[0][0] ] ), probs.append(k[0][1])\n",
    "\n",
    "lda_model.show_topics()\n",
    "nyt_df['Predicted Topic'] = topics\n",
    "nyt_df['Probability'] = probs\n",
    "dates = [row.split('T')[0] for row in nyt_df['pub_date'] ]\n",
    "nyt_df['pub_date'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting for the topics discussed in the results section only\n",
    "\n",
    "topic_name = ['Economy', 'Travel Restrictions', 'U.S Politics', 'Vaccination' ]\n",
    "\n",
    "dates = [row.split('T')[0] for row in nyt_df['pub_date'] ]\n",
    "nyt_df['pub_date'] = dates\n",
    "\n",
    "nyt_df['new_date'] =  pd.to_datetime(nyt_df['pub_date'], format='%Y-%m-%d')\n",
    "nyt_df = nyt_df.set_index('new_date', drop=True)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(topic_name)):\n",
    "    \n",
    "    x = nyt_df[nyt_df['Predicted Topic'] == topic_name[i] ]\n",
    "    curr = x.groupby(x.index.strftime('%Y-%m')).count()\n",
    "    curr = curr.reset_index()\n",
    "    curr['x_axis'] = pd.to_datetime(curr['new_date'], format='%Y-%m')\n",
    "\n",
    "    plt.plot(curr.x_axis, curr['Predicted Topic'], label = topic_name[i])\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "plt.savefig('nyt_alltopics_plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "FYLUf4Oc5pJR",
    "outputId": "9aafbc51-5305-4705-96fb-a92da9831f8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting for the topics \"Vaccination\" and \"Travel Restrictions\"\n",
    "\n",
    "topic_name = ['Vaccination', 'Travel Restrictions']\n",
    "\n",
    "dates = [row.split('T')[0] for row in nyt_df['pub_date'] ]\n",
    "nyt_df['pub_date'] = dates\n",
    "\n",
    "nyt_df['new_date'] =  pd.to_datetime(nyt_df['pub_date'], format='%Y-%m-%d')\n",
    "nyt_df = nyt_df.set_index('new_date', drop=True)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(topic_name)):\n",
    "    \n",
    "    x = nyt_df[nyt_df['Predicted Topic'] == topic_name[i] ]\n",
    "    curr = x.groupby(x.index.strftime('%Y-%m')).count()\n",
    "    curr = curr.reset_index()\n",
    "    curr['x_axis'] = pd.to_datetime(curr['new_date'], format='%Y-%m')\n",
    "\n",
    "    plt.plot(curr.x_axis, curr['Predicted Topic'], label = topic_name[i], color= \"red\")\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "plt.savefig('nyt_vaccine_travel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting for the topic \"Economy\"\n",
    "\n",
    "topic_name = ['Economy']\n",
    "\n",
    "dates = [row.split('T')[0] for row in nyt_df['pub_date'] ]\n",
    "nyt_df['pub_date'] = dates\n",
    "\n",
    "nyt_df['new_date'] =  pd.to_datetime(nyt_df['pub_date'], format='%Y-%m-%d')\n",
    "nyt_df = nyt_df.set_index('new_date', drop=True)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(topic_name)):\n",
    "    \n",
    "    x = nyt_df[nyt_df['Predicted Topic'] == topic_name[i] ]\n",
    "    curr = x.groupby(x.index.strftime('%Y-%m')).count()\n",
    "    curr = curr.reset_index()\n",
    "    curr['x_axis'] = pd.to_datetime(curr['new_date'], format='%Y-%m')\n",
    "\n",
    "    plt.plot(curr.x_axis, curr['Predicted Topic'], label = topic_name[i], color= 'blue')\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "plt.savefig('nyt_economy_')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting for the topic \"U.S Politics\"\n",
    "\n",
    "topic_name = ['U.S Politics']\n",
    "\n",
    "dates = [row.split('T')[0] for row in nyt_df['pub_date'] ]\n",
    "nyt_df['pub_date'] = dates\n",
    "\n",
    "nyt_df['new_date'] =  pd.to_datetime(nyt_df['pub_date'], format='%Y-%m-%d')\n",
    "nyt_df = nyt_df.set_index('new_date', drop=True)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(topic_name)):\n",
    "    \n",
    "    x = nyt_df[nyt_df['Predicted Topic'] == topic_name[i] ]\n",
    "    curr = x.groupby(x.index.strftime('%Y-%m')).count()\n",
    "    curr = curr.reset_index()\n",
    "    curr['x_axis'] = pd.to_datetime(curr['new_date'], format='%Y-%m')\n",
    "\n",
    "    plt.plot(curr.x_axis, curr['Predicted Topic'], label = topic_name[i], color= 'blue')\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "plt.savefig('us_politics_plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPa2iptm6QRH"
   },
   "outputs": [],
   "source": [
    "#saving as .csv\n",
    "\n",
    "import pandas as pd\n",
    "nyt_df.reset_index(drop=True, inplace=True)\n",
    "nyt_df.to_csv('nyt_topics.csv', index=True, columns=['pub_date', 'content', 'Predicted Topic'], sep=',')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cemkoyunch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
